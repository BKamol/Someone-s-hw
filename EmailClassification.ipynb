{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, SelectPercentile, f_classif\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmailPreprocess:\n",
    "    def __init__(self, filename):\n",
    "        self.filename = filename\n",
    "        self.data = None\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "        self.X_train = None\n",
    "        self.X_test = None\n",
    "        self.y_train = None\n",
    "        self.y_test = None\n",
    "        self.scaler = None\n",
    "        self.feature_selector = None\n",
    "        self.feature_selection_methods = ['KBest', 'Percentile']\n",
    "        \n",
    "    def load_data(self):\n",
    "        self.data = pd.read_csv(self.filename)\n",
    "\n",
    "    def check_missing_values(self):\n",
    "        cols = self.data.columns\n",
    "        cols_with_missing_values = [col for col in cols if self.data[col].isna().sum()]\n",
    "        if cols_with_missing_values:\n",
    "            for col in cols_with_missing_values:\n",
    "                self.data[col] = self.data[col].fillna(0)   \n",
    "        \n",
    "    def split_dataset(self):\n",
    "        self.X = self.data.iloc[:, 1:-1] # 提取标志\n",
    "        self.y = self.data.iloc[:, -1] # 提取标签\n",
    "\n",
    "    def feature_scaling(self, method='MinMax'):\n",
    "        \"\"\"\n",
    "        Метод для масштабирования признаков.\n",
    "        method: 'MinMax', 'Standard'\n",
    "        \"\"\"\n",
    "        if (method == 'Standard'):\n",
    "            self.scaler = StandardScaler().fit(self.X)\n",
    "        elif (method == 'MinMax'):\n",
    "            self.scaler = MinMaxScaler().fit(self.X)\n",
    "        else:\n",
    "            return NotImplemented\n",
    "        self.X = pd.DataFrame(self.scaler.transform(self.X), columns=self.X.columns) # 缩放功能\n",
    "\n",
    "    def train_test_split(self, test_size=0.2, random_state=42):\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.X, self.y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "    def feature_selection(self, method='KBest', k=10):\n",
    "        \"\"\"\n",
    "        Метод для отбора k лучших признаков.\n",
    "        method: 'Kbest', 'Percentile'.\n",
    "        Записывает лучше признаки в атрибут X_best_features\n",
    "        \"\"\"\n",
    "        if (method == 'Percentile'):\n",
    "            percentile = k/self.X.shape[1]*100\n",
    "            self.feature_selector = SelectPercentile(f_classif, percentile=percentile).fit(self.X, self.y)\n",
    "        elif (method == 'KBest'):\n",
    "            self.feature_selector = SelectKBest(f_classif, k=k).fit(self.X, self.y)\n",
    "        else:\n",
    "            return NotImplemented\n",
    "        self.X_best_feats = pd.DataFrame(self.feature_selector.transform(self.X), columns=self.feature_selector.get_feature_names_out()) # 最佳功能\n",
    "\n",
    "    def text_cleaning(self):\n",
    "        \"\"\"\n",
    "        Метод для очистки стоп слов \n",
    "        \"\"\"\n",
    "        STOPWORDS = stopwords.words('english')\n",
    "        for word in STOPWORDS:\n",
    "            if word in self.X.columns:\n",
    "                self.X = self.X.drop(word, axis=1)\n",
    "\n",
    "    def preprocess(self):\n",
    "        self.load_data()\n",
    "        self.check_missing_values()\n",
    "        self.split_dataset()\n",
    "        self.text_cleaning()\n",
    "        self.feature_scaling()\n",
    "        self.train_test_split()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmailClassifier(EmailPreprocess):\n",
    "    def __init__(self, filename):\n",
    "        super().__init__(filename)\n",
    "        self.preprocess()\n",
    "        self.best_fitted_model = None\n",
    "        self.best_roc_auc_score = None  # 我们将根据roc auc选择最佳型号\n",
    "        self.clusterer = None\n",
    "\n",
    "    def find_best_model_and_params(self):\n",
    "        \"\"\"\n",
    "        Метод для поиска лучшей модели и ее параметров.\n",
    "        Записывает лучшую модель в self.best_fitted_model.\n",
    "        \"\"\"\n",
    "        models = [KNeighborsClassifier(), LogisticRegression(), MultinomialNB(), RandomForestClassifier()]  \n",
    "        self.best_roc_auc_score = 0\n",
    "\n",
    "        for model in models:\n",
    "            scores = cross_validate(model, self.X, self.y, cv=3, scoring=('accuracy', 'f1', 'precision', 'recall', 'roc_auc'))\n",
    "            roc_auc_score = max(scores['test_roc_auc'])\n",
    "            if roc_auc_score > self.best_roc_auc_score:\n",
    "                self.best_roc_auc_score = roc_auc_score\n",
    "                self.best_fitted_model = model\n",
    "\n",
    "        self.best_fitted_model.fit(self.X_train, self.y_train)\n",
    "\n",
    "    def evaluate_test_metrics(self):\n",
    "        \"\"\"\n",
    "        Метод для оценки метрик лучшей модели на тестовом наборе данных.\n",
    "        Возвращает словарь с метриками.\n",
    "        \"\"\"\n",
    "        if self.best_fitted_model is None:\n",
    "            raise ValueError(\"Лучшая модель не найдена. Сначала запустите find_best_model_and_params()\")\n",
    "        \n",
    "        y_pred = self.best_fitted_model.predict(self.X_test)\n",
    "        accuracy = accuracy_score(self.y_test, y_pred)\n",
    "        f1 = f1_score(self.y_test, y_pred)\n",
    "        precision = precision_score(self.y_test, y_pred)\n",
    "        recall = recall_score(self.y_test, y_pred)\n",
    "        return {\n",
    "        'accuracy': accuracy,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "        }\n",
    "    \n",
    "    def cluster_emails(self, method='kmeans'):\n",
    "        \"\"\"\n",
    "        Метод для кластеризации электронных писем на два кластера.\n",
    "        method: 'kmeans', 'hierarchical' или 'dbscan'.\n",
    "        Возвращает два значения: процент данных, соответствующих спаму в каждом\n",
    "        кластере.\n",
    "        \"\"\"\n",
    "        if method == 'kmeans':\n",
    "            self.clusterer = KMeans(n_clusters=2).fit(self.X)\n",
    "        elif method == 'dbscan':\n",
    "            self.clusterer = DBSCAN(eps=4).fit(self.X)\n",
    "        elif method == 'hierarchal':\n",
    "            self.clusterer = AgglomerativeClustering(n_clusters=2).fit(self.X)\n",
    "        else:\n",
    "            return NotImplemented\n",
    "\n",
    "        y_and_clusters = pd.concat([self.y, pd.Series(self.clusterer.labels_, name='Cluster')], axis=1)\n",
    "        cond0 = (y_and_clusters['Cluster'] == 0) & (y_and_clusters['Prediction'] == 1)\n",
    "        cond1 = (y_and_clusters['Cluster'] == 1) & (y_and_clusters['Prediction'] == 1)\n",
    "\n",
    "        return (round(y_and_clusters[cond0].shape[0]/y_and_clusters[y_and_clusters['Cluster'] == 0].shape[0] * 100, 2), \n",
    "                round(y_and_clusters[cond1].shape[0]/y_and_clusters[y_and_clusters['Cluster'] == 1].shape[0] * 100, 2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = EmailClassifier('emails.csv')\n",
    "clf.find_best_model_and_params()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.9729468599033816, 'f1': 0.9533333333333334, 'precision': 0.9407894736842105, 'recall': 0.9662162162162162}\n"
     ]
    }
   ],
   "source": [
    "print(clf.evaluate_test_metrics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28.46, 95.24)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.cluster_emails()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
